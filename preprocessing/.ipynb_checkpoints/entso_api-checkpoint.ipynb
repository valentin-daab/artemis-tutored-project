{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e0b2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import country_converter as coco\n",
    "\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbb3c4",
   "metadata": {},
   "source": [
    "# Installed Capacity per Production Type (yearly from 2000 to 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f92526",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = EntsoePandasClient(api_key=\"\")\n",
    "\n",
    "start = pd.Timestamp('20000101', tz='Europe/Brussels')\n",
    "end   = pd.Timestamp('20200102', tz='Europe/Brussels')\n",
    "\n",
    "country_code = ['AL', 'AT', 'BE', 'BA', 'BG', 'HR', 'CY', 'CZ', \n",
    "                'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', \n",
    "                'IT', 'LV', 'LT', 'LU', 'ME', 'NL', 'MK', 'NO', \n",
    "                'PL', 'PT', 'RO', 'RS', 'SK', 'SI', 'ES', 'SE', \n",
    "                'CH', 'UA', 'UK', 'GE', 'XK']\n",
    "\n",
    "cc = coco.CountryConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731830cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL AT BE BA BG HR CY CZ DK EE FI FR DE GR HU IE IT LV LT LU ME NL MK NO PL PT RO RS SK SI ES SE CH UA UK \n",
      "GE not available\n",
      "\n",
      "XK not available\n",
      "8min 23s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for count, value in enumerate(country_code) :\n",
    "    \n",
    "    try :\n",
    "        temp_df = client.query_installed_generation_capacity(value, start=start,end=end, psr_type=None)\n",
    "    except :\n",
    "        print(f\"\\n{value} not available\")\n",
    "        continue\n",
    "        \n",
    "    temp_df.insert(0, 'Country', value)\n",
    "    temp_df.index = temp_df.index.tz_localize(None)\n",
    "    \n",
    "    df = pd.concat([df, temp_df])\n",
    "    print(value, end=' ')\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "df['Country'] = cc.pandas_convert(series=df['Country'], to='short_name') \n",
    "df.to_excel(\"icppt.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d7faa",
   "metadata": {},
   "source": [
    "# Actual generation per production type (monthly 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c510a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE 3min 49s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "start = pd.Timestamp('20220101', tz='Europe/Brussels')\n",
    "end   = pd.Timestamp('20230101', tz='Europe/Brussels')\n",
    "\n",
    "for count, value in enumerate(country_code) :\n",
    "    \n",
    "    try :\n",
    "        df = client.query_generation(value, start=start,end=end, psr_type=None)\n",
    "    except :\n",
    "        print(f\"\\n{value} not available\")\n",
    "        continue\n",
    "        \n",
    "    df.insert(0, 'Country', value)\n",
    "    df.index = df.index.tz_localize(None)\n",
    "    df['Country'] = cc.pandas_convert(series=df['Country'], to='short_name') \n",
    "    \n",
    "    with pd.ExcelWriter(\"agppt.xlsx\", mode=\"a\", engine=\"openpyxl\") as writer :\n",
    "        df.to_excel(writer, sheet_name = value)\n",
    "        \n",
    "    print(value, end = \" \")\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182cfc5",
   "metadata": {},
   "source": [
    "# Actual generation per generation unit\n",
    "## June & January 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4c2ae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoMatchingDataError: between 2022-01-01 00:00:00+01:00 and 2022-01-02 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-02 00:00:00+01:00 and 2022-01-03 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-03 00:00:00+01:00 and 2022-01-04 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-04 00:00:00+01:00 and 2022-01-05 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-05 00:00:00+01:00 and 2022-01-06 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-06 00:00:00+01:00 and 2022-01-07 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-07 00:00:00+01:00 and 2022-01-08 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-08 00:00:00+01:00 and 2022-01-09 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-09 00:00:00+01:00 and 2022-01-10 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-10 00:00:00+01:00 and 2022-01-11 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-11 00:00:00+01:00 and 2022-01-12 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-14 00:00:00+01:00 and 2022-01-15 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-15 00:00:00+01:00 and 2022-01-16 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-16 00:00:00+01:00 and 2022-01-17 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-17 00:00:00+01:00 and 2022-01-18 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-18 00:00:00+01:00 and 2022-01-19 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-19 00:00:00+01:00 and 2022-01-20 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-20 00:00:00+01:00 and 2022-01-21 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-21 00:00:00+01:00 and 2022-01-22 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-22 00:00:00+01:00 and 2022-01-23 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-23 00:00:00+01:00 and 2022-01-24 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-24 00:00:00+01:00 and 2022-01-25 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-25 00:00:00+01:00 and 2022-01-26 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-26 00:00:00+01:00 and 2022-01-27 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-27 00:00:00+01:00 and 2022-01-28 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-28 00:00:00+01:00 and 2022-01-29 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-29 00:00:00+01:00 and 2022-01-30 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-30 00:00:00+01:00 and 2022-01-31 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-31 00:00:00+01:00 and 2022-02-01 00:00:00+01:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL\n",
      "AT\n",
      "BE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoMatchingDataError: between 2022-01-13 00:00:00+01:00 and 2022-01-14 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-14 00:00:00+01:00 and 2022-01-15 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-15 00:00:00+01:00 and 2022-01-16 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-16 00:00:00+01:00 and 2022-01-17 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-17 00:00:00+01:00 and 2022-01-18 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-18 00:00:00+01:00 and 2022-01-19 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-19 00:00:00+01:00 and 2022-01-20 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-20 00:00:00+01:00 and 2022-01-21 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-21 00:00:00+01:00 and 2022-01-22 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-22 00:00:00+01:00 and 2022-01-23 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-23 00:00:00+01:00 and 2022-01-24 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-24 00:00:00+01:00 and 2022-01-25 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-25 00:00:00+01:00 and 2022-01-26 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-26 00:00:00+01:00 and 2022-01-27 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-27 00:00:00+01:00 and 2022-01-28 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-28 00:00:00+01:00 and 2022-01-29 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-29 00:00:00+01:00 and 2022-01-30 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-30 00:00:00+01:00 and 2022-01-31 00:00:00+01:00\n",
      "NoMatchingDataError: between 2022-01-31 00:00:00+01:00 and 2022-02-01 00:00:00+01:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA\n",
      "BG\n",
      "\n",
      "HR not available\n",
      "\n",
      "CY not available\n",
      "CZ\n",
      "\n",
      "DK not available\n",
      "EE\n",
      "FI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daabv\\AppData\\Local\\Temp\\ipykernel_13680\\3941319514.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(0, 'Country', value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR\n",
      "\n",
      "DE not available\n",
      "GR\n",
      "HU\n",
      "IE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daabv\\AppData\\Local\\Temp\\ipykernel_13680\\3941319514.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(0, 'Country', value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT\n",
      "LV\n",
      "LT\n",
      "\n",
      "LU not available\n",
      "ME\n",
      "NL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NoMatchingDataError: between 2022-01-12 00:00:00+01:00 and 2022-01-13 00:00:00+01:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MK\n",
      "NO\n",
      "PL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daabv\\AppData\\Local\\Temp\\ipykernel_13680\\3941319514.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df.insert(0, 'Country', value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PT\n",
      "RO\n",
      "RS\n",
      "SK\n",
      "SI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection Error, retrying in 0 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ES not available\n",
      "SE\n",
      "CH\n",
      "\n",
      "UA not available\n",
      "\n",
      "UK not available\n",
      "\n",
      "GE not available\n",
      "XK\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "start = pd.Timestamp('20220101', tz='Europe/Brussels')\n",
    "end   = pd.Timestamp('20220201', tz='Europe/Brussels')\n",
    "\n",
    "for count, value in enumerate(country_code) :\n",
    "    \n",
    "    try :\n",
    "        df = client.query_generation_per_plant(value, start=start,end=end, psr_type=None)\n",
    "    except :\n",
    "        print(f\"\\n{value} not available\")\n",
    "        continue\n",
    "        \n",
    "    df.insert(0, 'Country', value)\n",
    "    df.index = df.index.tz_localize(None)\n",
    "    df['Country'] = cc.pandas_convert(series=df['Country'], to='short_name') \n",
    "    \n",
    "    \n",
    "    with pd.ExcelWriter(\"agppu.xlsx\", mode=\"a\", engine=\"openpyxl\") as writer :\n",
    "        df.to_excel(writer, sheet_name = value)\n",
    "        \n",
    "    print(value)\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e43624",
   "metadata": {},
   "source": [
    "# Installed capacity per production unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e54f862",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AL\n",
      "AT\n",
      "BE\n",
      "BA\n",
      "BG\n",
      "\n",
      "HR not available\n",
      "\n",
      "CY not available\n",
      "CZ\n",
      "\n",
      "DK not available\n",
      "EE\n",
      "FI\n",
      "FR\n",
      "\n",
      "DE not available\n",
      "GR\n",
      "HU\n",
      "IE\n",
      "IT\n",
      "LV\n",
      "LT\n",
      "\n",
      "LU not available\n",
      "ME\n",
      "NL\n",
      "MK\n",
      "NO\n",
      "PL\n",
      "PT\n",
      "RO\n",
      "RS\n",
      "SK\n",
      "SI\n",
      "ES\n",
      "SE\n",
      "CH\n",
      "\n",
      "UA not available\n",
      "\n",
      "UK not available\n",
      "\n",
      "GE not available\n",
      "\n",
      "XK not available\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "country_code = ['AL', 'AT', 'BE', 'BA', 'BG', 'HR', 'CY', 'CZ', \n",
    "                'DK', 'EE', 'FI', 'FR', 'DE', 'GR', 'HU', 'IE', \n",
    "                'IT', 'LV', 'LT', 'LU', 'ME', 'NL', 'MK', 'NO', \n",
    "                'PL', 'PT', 'RO', 'RS', 'SK', 'SI', 'ES', 'SE', \n",
    "                'CH', 'UA', 'UK', 'GE', 'XK']\n",
    "\n",
    "start = pd.Timestamp('20200101', tz='Europe/Brussels')\n",
    "end   = pd.Timestamp('20210102', tz='Europe/Brussels')\n",
    "\n",
    "for count, value in enumerate(country_code) :\n",
    "    try :\n",
    "        temp_df = client.query_installed_generation_capacity_per_unit(value, start=start,end=end, psr_type=None)\n",
    "    except :\n",
    "        print(f\"\\n{value} not available\")\n",
    "        continue\n",
    "        \n",
    "    temp_df.insert(0, 'Country', value)\n",
    "    df = pd.concat([df, temp_df])\n",
    "    print(value)\n",
    "    temp_df = pd.DataFrame()\n",
    "\n",
    "df['Country'] = cc.pandas_convert(series=df['Country'], to='short_name') \n",
    "df.to_excel(\"icppu_2020.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
